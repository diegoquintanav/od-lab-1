{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OD Lab 1, part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.4 (default, Oct 15 2019, 22:29:14) \\n[GCC 7.4.0]'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "from pprint import pprint as pp\n",
    "random.seed(42)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.6\n",
      "4.3.0\n"
     ]
    }
   ],
   "source": [
    "import neo4j\n",
    "import py2neo\n",
    "print(neo4j.__version__)\n",
    "print(py2neo.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# instantiate driver\n",
    "NEO4J_URI=\"bolt://localhost:7687\"\n",
    "gdb = GraphDatabase.driver(uri=NEO4J_URI, auth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Neo4j Kernel', 'version': '3.5.15', 'edition': 'enterprise'}]\n"
     ]
    }
   ],
   "source": [
    "with gdb.session() as session:\n",
    "    print(session.run(\n",
    "        \"call dbms.components() yield name, versions, edition unwind versions as version return name, version, edition;\").data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2 Loading Data\n",
    "\n",
    "\n",
    "We will read data from https://dblp.uni-trier.de/. From the XML's description of data in https://dblp.org/faq/16154937.html, the following elements are represented\n",
    "\n",
    "> - article – An article from a journal or magazine.\n",
    "> - inproceedings – A paper in a conference or workshop proceedings.\n",
    "> - proceedings – The proceedings volume of a conference or workshop.\n",
    "> - book – An authored monograph or an edited collection of articles.\n",
    "> - incollection – A part or chapter in a monograph.\n",
    "> - phdthesis – A PhD thesis.\n",
    "> - mastersthesis – A Master's thesis. There are only very few Master's theses in dblp.\n",
    "> - www – A web page. There are only very few web pages in dblp. See also the notes on person records.\n",
    "\n",
    "We will rely on the script provided in https://github.com/ThomHurks/dblp-to-csv, and we will be removing some of the elements by editing from the `dtd` file, because they are out of the scope of the laboratory. In particular we will be removing\n",
    "\n",
    "- book\n",
    "- incollection\n",
    "- phdthesis\n",
    "- masterthesis\n",
    "- www\n",
    "\n",
    "Find the modified version of the dtd file in the github repository in https://github.com/diegoquintanav/od-lab-1/blob/master/notebooks/dblp-raw/dblp_slim.dtd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n",
      "<!DOCTYPE dblp SYSTEM \"dblp.dtd\">\n",
      "<dblp>\n",
      "<article mdate=\"2018-01-07\" key=\"tr/meltdown/s18\" publtype=\"informal\">\n",
      "<author>Paul Kocher</author>\n",
      "<author>Daniel Genkin</author>\n",
      "<author>Daniel Gruss</author>\n",
      "<author>Werner Haas</author>\n",
      "<author>Mike Hamburg</author>\n",
      "<author>Moritz Lipp</author>\n"
     ]
    }
   ],
   "source": [
    "!head \"dblp-raw/dblp.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,7G\tdblp-raw/dblp.xml\n"
     ]
    }
   ],
   "source": [
    "# size of xml file\n",
    "!du -h \"dblp-raw/dblp.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting XML to CSV\n",
    "\n",
    "The script mentioned earlier is executed as\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "./XMLToCSV.py --annotate --neo4j dblp-raw/dblp.xml dblp-raw/dblp_slim.dtd output_slim/output.csv --relations author:authored_by journal:published_in publisher:published_by school:submitted_at editor:edited_by cite:has_citation\n",
    "```\n",
    "\n",
    "and the resulting `neo4j-admin import` command is\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "neo4j-admin import --mode=csv --database=dblp_slim.db --delimiter \";\" --array-delimiter \"|\" --id-type INTEGER --nodes:inproceedings \"output_slim/output_inproceedings_header.csv,output_slim/output_inproceedings.csv\" --nodes:article \"output_slim/output_article_header.csv,output_slim/output_article.csv\" --nodes:proceedings \"output_slim/output_proceedings_header.csv,output_slim/output_proceedings.csv\" --nodes:editor \"output_slim/output_editor.csv\" --relationships:edited_by \"output_slim/output_editor_edited_by.csv\" --nodes:publisher \"output_slim/output_publisher.csv\" --relationships:published_by \"output_slim/output_publisher_published_by.csv\" --nodes:journal \"output_slim/output_journal.csv\" --relationships:published_in \"output_slim/output_journal_published_in.csv\" --nodes:author \"output_slim/output_author.csv\" --relationships:authored_by \"output_slim/output_author_authored_by.csv\" --nodes:cite \"output_slim/output_cite.csv\" --relationships:has_citation \"output_slim/output_cite_has_citation.csv\"\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "By modifying the `dtd` file, we obtained a smaller graph\n",
    "- node count from 9,985,270 to 7,338, 701\n",
    "- relationship count from 19,917,751 to 17,079,387\n",
    "\n",
    "Finally, by running `call db.schema.visualization()` we get something like this\n",
    "\n",
    "![schema1](schemas/dblp_slim_before/graph.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neo4j_import.sh\t\t       output_inproceedings.csv\n",
      "output_article.csv\t       output_inproceedings_header.csv\n",
      "output_article_header.csv      output_journal.csv\n",
      "output_author_authored_by.csv  output_journal_published_in.csv\n",
      "output_author.csv\t       output_proceedings.csv\n",
      "output_cite.csv\t\t       output_proceedings_header.csv\n",
      "output_cite_has_citation.csv   output_publisher.csv\n",
      "output_editor.csv\t       output_publisher_published_by.csv\n",
      "output_editor_edited_by.csv\n"
     ]
    }
   ],
   "source": [
    "!ls output_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0;Daniel Genkin|Daniel Gruss|Michael Schwarz 0001|Mike Hamburg|Moritz Lipp|Paul Kocher|Stefan Mangard|Thomas Prescher 0002|Werner Haas|Yuval Yarom;;;;;;;;;;;https://spectreattack.com/spectre.pdf;;;meltdownattack.com;tr/meltdown/s18;2018-01-07;;;;;;;informal;;;Spectre Attacks: Exploiting Speculative Execution.;;;;;2018\n",
      "1;Daniel Genkin|Daniel Gruss|Michael Schwarz 0001|Mike Hamburg|Moritz Lipp|Paul Kocher|Stefan Mangard|Thomas Prescher 0002|Werner Haas|Yuval Yarom;;;;;;;;;;;https://meltdownattack.com/meltdown.pdf;;;meltdownattack.com;tr/meltdown/m18;2018-01-07;;;;;;;informal;;;Meltdown;;;;;2018\n",
      "2;Frank Manola;;;;;;;;;;;;;;GTE Laboratories Incorporated;tr/gte/TR-0263-08-94-165;2019-10-25;August;;;;;;informal;;;An Evaluation of Object-Oriented DBMS Developments: 1994 Edition.;;;db/journals/gtelab/index.html#TR-0263-08-94-165;TR-0263-08-94-165;1994\n",
      "3;Michael L. Brodie|Michael Stonebraker;;;;;;;;;;;;;;GTE Laboratories Incorporated;tr/gte/TR-0222-10-92-165;2019-10-25;March;This report is also available as a Technical Memorandum of Electronics Research Laboratory, College of Engineering, University of California, Berkeley.;;;;;informal;;;DARWIN: On the Incremental Migration of Legacy Information Systems;;;db/journals/gtelab/index.html#TR-0222-10-92-165;TR-0222-10-92-165;1993\n",
      "4;Farshad Nayeri|Joe D. Morrison|Mark F. Hornick;;;;;;;;;;;;;;GTE Laboratories Incorporated;tr/gte/TR-0174-12-91-165;2019-10-25;December;;;;;;informal;;;Integrating Heterogeneous, Autonomous, Distributed Applications Using the DOM Prototype.;;;db/journals/gtelab/index.html#TR-0174-12-91-165;TR-0174-12-91-165;1991\n",
      "5;Frank Manola;;;;;;;;;;;;;;GTE Laboratories Incorporated;tr/gte/TM-0149-06-89-165;2019-10-25;June;;;;;;informal;;;Object Model Capabilities For Distributed Object Management.;;;db/journals/gtelab/index.html#TM-0149-06-89-165;TM-0149-06-89-165;1989\n",
      "6;Frank Manola;;;;;;;;;;;;;;GTE Laboratories Incorporated;tr/gte/TR-0310-11-95-165;2019-10-25;November;;;;;;informal;;;Integrating Object-Oriented Applications and Middleware with Relational Databases.;;;db/journals/gtelab/index.html#TR-0310-11-95-165;TR-0310-11-95-165;1995\n",
      "7;Alejandro P. Buchmann|Dimitrios Georgakopoulos|M. Tamer Özsu;;;;;;;;;;;;;;GTE Laboratories Incorporated;tr/gte/TR-0146-06-91-165;2019-10-25;June;;;;;;informal;;;Towards a Transaction Management System for DOM.;;;db/journals/gtelab/index.html#TR-0146-06-91-165;TR-0146-06-91-165;1991\n",
      "8;Frank Manola|Sandra Heiler;;;;;;;;;;;;;;GTE Laboratories Incorporated;tr/gte/TR-0231-08-93-165;2019-10-25;August;;;;;;informal;;;A 'RISC' Object Model for Object System Interoperation: Concepts and Applications.;;;db/journals/gtelab/index.html#TR-0231-08-93-165;TR-0231-08-93-165;1993\n",
      "9;Frank Manola;;;;;;;;;;;;;;GTE Laboratories Incorporated;tr/gte/TR-0244-12-93-165;2019-10-25;December;;;;;;informal;;;MetaObject Protocol Concepts for a RISC Object Model.;;;db/journals/gtelab/index.html#TR-0244-12-93-165;TR-0244-12-93-165;1993\n"
     ]
    }
   ],
   "source": [
    "!head output_slim/output_article.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing nodes and relationships\n",
    "\n",
    "We are then missing the following nodes\n",
    "\n",
    "- topics\n",
    "- keywords\n",
    "- journals\n",
    "- volumes\n",
    "\n",
    "and the following relationships\n",
    "\n",
    "- topic -> has -> keywords\n",
    "- article -> cited_by -> article\n",
    "- author -> reviews -> article\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake citations\n",
    "\n",
    "\n",
    "citations are hard to parse from xml data, so we will be **randomly** linking articles between them using the `cited_in` relationship\n",
    "\n",
    "- creating a relationship, using the nodes\n",
    "\n",
    "```cypher\n",
    "MATCH (a:article),(b:article)\n",
    "WHERE ID(a) = 12 AND ID(b) = 13\n",
    "CREATE (a)-[r:cited_by]->(b)\n",
    "RETURN type(r)\n",
    "```\n",
    "\n",
    "- deleting all relationships\n",
    "\n",
    "```cypher\n",
    "MATCH p=(:article)-[r:cited_by]->(:article) DELETE r\n",
    "```\n",
    "\n",
    "- query relationships\n",
    "\n",
    "```cypher\n",
    "MATCH p=(:article)-[r:cited_by]->(:article) RETURN p LIMIT 25\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating citations, we need to fetch the IDs of existing articles. We will be creating citations only between `article` nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2470775, 2470776, 2470777, 2470778, 2470779]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_article_ids = \"MATCH (n:article) RETURN ID(n) LIMIT 10000\"\n",
    "\n",
    "with gdb.session() as session:\n",
    "    article_ids = [v[0] for v in session.run(q_article_ids).values()]\n",
    "    \n",
    "article_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'COUNT(r)': 0}]\n"
     ]
    }
   ],
   "source": [
    "# delete existing citations before inserting new ones\n",
    "with gdb.session() as session:\n",
    "    _out = session.run(\"MATCH p=(:article)-[r:cited_by]->(:article) DELETE r RETURN COUNT(r)\")\n",
    "    print(_out.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `cited_by` relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://neo4j.com/docs/driver-manual/1.7/sessions-transactions/#driver-transactions-transaction-functions\n",
    "\n",
    "q_add_citation_rel_id = \"\"\"MATCH (a:article),(b:article)\n",
    "WHERE ID(a) = $id_a AND ID(b) = $id_b\n",
    "CREATE p=(a)-[r:cited_by]->(b)\n",
    "RETURN p\"\"\"\n",
    "\n",
    "\n",
    "def add_citation_rel(driver, id_a, id_b):\n",
    "    with driver.session() as session:\n",
    "        # Caller for transactional unit of work\n",
    "        return session.write_transaction(create_citation_rel, id_a, id_b)\n",
    "\n",
    "# Simple implementation of the unit of work\n",
    "def create_citation_rel(tx, id_a, id_b):\n",
    "    return tx.run(q_add_citation_rel_id, id_a=id_a, id_b = id_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 500 relationships of type `cited_by`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping:  2551992 2551992\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "# pick a sample of 500 papers, and make them be cited by other three papers at random\n",
    "created_citations = []\n",
    "\n",
    "for article in random.sample(article_ids, 500):\n",
    "    for citation in random.sample(article_ids, 3):\n",
    "        if article != citation: # they can't cite themselves\n",
    "            _out = add_citation_rel(gdb, id_a=article, id_b=citation)\n",
    "            created_citations.append(_out.data())\n",
    "        else:\n",
    "            print(\"Skipping: \",article, citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p': <Path start=<Node id=2545142 labels={'article'} properties={'volume': '94-17', 'journal': 'Universität Trier, Mathematik/Informatik, Forschungsbericht', 'mdate': neotime.Date(2017, 6, 8), 'year': 1994, 'author': ['Anna Slobodová', 'Christoph Meinel'], 'publtype': 'informal', 'title': 'A Unifying Theoretical Background for Some BDD-based Data Structures', 'article': 401, 'key': 'tr/trier/MI94-17'}> end=<Node id=2561995 labels={'article'} properties={'ee': ['https://doi.org/10.1016/j.compchemeng.2008.08.009'], 'year': 2009, 'author': ['Alexandre C. Dimian', 'Costin Sorin Bildea', 'Klaas Steur', 'Pietro Altimari'], 'title': 'Steady-state behaviour of PFR-separation-recycle systems with simultaneous exothermic and endothermic, first-order reactions.', 'article': 7431, 'url': 'db/journals/cce/cce33.html#SteurBAD09', 'volume': '33', 'number': '3', 'journal': 'Computers & Chemical Engineering', 'pages': '628-635', 'mdate': neotime.Date(2017, 6, 5), 'author-orcid': ['0000-0001-7707-1366', '0000-0002-6638-1091'], 'key': 'journals/cce/SteurBAD09'}> size=1>}]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_citations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make articles `UNIQUE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no repeated articles\n",
    "with gdb.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:article) ASSERT n.article IS UNIQUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r': <Relationship id=17081984 nodes=(<Node id=2470781 labels=set() properties={}>, <Node id=2554932 labels=set() properties={}>) type='cited_by' properties={}>}\n",
      "{'r': <Relationship id=17081983 nodes=(<Node id=2470781 labels=set() properties={}>, <Node id=2560494 labels=set() properties={}>) type='cited_by' properties={}>}\n",
      "{'r': <Relationship id=17081982 nodes=(<Node id=2470781 labels=set() properties={}>, <Node id=2559104 labels=set() properties={}>) type='cited_by' properties={}>}\n",
      "{'r': <Relationship id=17081031 nodes=(<Node id=2470784 labels=set() properties={}>, <Node id=2560355 labels=set() properties={}>) type='cited_by' properties={}>}\n",
      "{'r': <Relationship id=17081030 nodes=(<Node id=2470784 labels=set() properties={}>, <Node id=2552977 labels=set() properties={}>) type='cited_by' properties={}>}\n"
     ]
    }
   ],
   "source": [
    "with gdb.session() as session:\n",
    "    _out = session.run(\"MATCH p=(:article)-[r:cited_by]->(:article) RETURN r LIMIT 5\")\n",
    "    for elem in _out.data():\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake keywords\n",
    "It's not trivial to parse keywords and topics from data, so we will fake some topics and random keywords using the `faker` library (https://faker.readthedocs.io/en/master/) as explained in http://www.jexp.de/blog/html/create_random_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "from faker.providers import lorem\n",
    "\n",
    "fake = Faker()\n",
    "fake.seed_instance(42)\n",
    "fake.add_provider(lorem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# +-100 fake, non repeated keywords\n",
    "fake_keywords = [\n",
    "    (ix, word) for ix, word in enumerate(\n",
    "        list(\n",
    "            {fake.sentence(nb_words=3).rstrip('.') for _ in range(100)}\n",
    "        ), start=1)]\n",
    "len(fake_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Partner rest measure'),\n",
       " (2, 'Former reflect even'),\n",
       " (3, 'Ball character him'),\n",
       " (4, 'Career left anyone'),\n",
       " (5, 'Each'),\n",
       " (6, 'Machine dream key'),\n",
       " (7, 'Option production base'),\n",
       " (8, 'Remember'),\n",
       " (9, 'Knowledge city technology'),\n",
       " (10, 'Build movie several')]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_keywords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'COUNT(n)': 0}]\n"
     ]
    }
   ],
   "source": [
    "# delete keywords\n",
    "with gdb.session() as session:\n",
    "    _out = session.run(\"MATCH (n:keyword) DELETE n RETURN COUNT(n)\")\n",
    "    print(_out.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_create_keyword = \"CREATE (n:keyword {id:$id, keyword:$keyword}) RETURN n\"\n",
    "\n",
    "created_keywords = []\n",
    "\n",
    "with gdb.session() as session:\n",
    "    for ix, keyword in fake_keywords:\n",
    "        _out = session.run(q_create_keyword, id=ix, keyword=keyword)\n",
    "        created_keywords.append(_out.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n': <Node id=7340970 labels={'keyword'} properties={'keyword': 'Partner rest measure', 'id': 1}>}]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_keywords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create UNIQUE constraint\n",
    "with gdb.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT ON (n:keyword) ASSERT n.keyword IS UNIQUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign 5 keywords to 1000 articles, at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'COUNT(r)': 0}]\n"
     ]
    }
   ],
   "source": [
    "# delete relationships\n",
    "with gdb.session() as session:\n",
    "    _out = session.run(\"MATCH p=(:article)-[r:has_keyword]->(:keyword) DELETE r RETURN COUNT(r)\")\n",
    "    print(_out.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign 5 keywords randomly to 1000 articles\n",
    "random.seed(42)\n",
    "\n",
    "q_add_keywords = \"\"\"MATCH (a:article),(b:keyword)\n",
    "WHERE ID(a) = $article_id AND b.keyword = $keyword\n",
    "CREATE p=(a)-[r:has_keyword]->(b)\n",
    "RETURN p\"\"\"\n",
    "\n",
    "created_kw_rel = []\n",
    "\n",
    "with gdb.session() as session:\n",
    "    for article_id in random.sample(article_ids, 1000):\n",
    "        for ix, keyword in random.sample(fake_keywords, 5):\n",
    "            _out = session.run(q_add_keywords, article_id=article_id, keyword=keyword)\n",
    "            created_kw_rel.append(_out.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p': <Path start=<Node id=2545142 labels={'article'} properties={'volume': '94-17', 'journal': 'Universität Trier, Mathematik/Informatik, Forschungsbericht', 'mdate': neotime.Date(2017, 6, 8), 'year': 1994, 'author': ['Anna Slobodová', 'Christoph Meinel'], 'publtype': 'informal', 'title': 'A Unifying Theoretical Background for Some BDD-based Data Structures', 'article': 401, 'key': 'tr/trier/MI94-17'}> end=<Node id=7341069 labels={'keyword'} properties={'keyword': 'Deep something future', 'id': 81}> size=1>}]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_kw_rel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p': <Path start=<Node id=2534363 labels={'article'} properties={'ee': ['https://doi.org/10.1007/s13222-016-0230-9'], 'year': 2016, 'author': ['Theo Härder'], 'title': 'Prof. Dr. Dr. h.\\u202fc. Hans-Jürgen Appelrath.', 'article': 101838, 'url': 'db/journals/dbsk/dbsk16.html#Harder16', 'volume': '16', 'number': '3', 'journal': 'Datenbank-Spektrum', 'pages': '259-260', 'mdate': neotime.Date(2018, 6, 26), 'ee-type': ['oa'], 'key': 'journals/dbsk/Harder16'}> end=<Node id=7340970 labels={'keyword'} properties={'keyword': 'Partner rest measure', 'id': 1}> size=1>}\n"
     ]
    }
   ],
   "source": [
    "with gdb.session() as session:\n",
    "    _out = session.run(\"MATCH p=(:article)-[r:has_keyword]->(:keyword) RETURN p LIMIT 5\")\n",
    "    print(_out.data()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faking reviewers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a `reviewed_by` relationship between authors and articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'COUNT(r)': 0}]\n"
     ]
    }
   ],
   "source": [
    "# delete relationships\n",
    "with gdb.session() as session:\n",
    "    _out = session.run(\"MATCH p=(:article)-[r:reviewed_by]->(:author) DELETE r RETURN COUNT(r)\")\n",
    "    print(_out.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4779298, 4779299, 4779300, 4779301, 4779302]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_author_ids = \"MATCH (n:author) RETURN ID(n) LIMIT 10000\"\n",
    "\n",
    "with gdb.session() as session:\n",
    "    author_ids = [v[0] for v in session.run(q_author_ids).values()]\n",
    "    \n",
    "author_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign between 3 and 4 reviewers randomly to 1000 articles\n",
    "random.seed(42)\n",
    "\n",
    "q_add_reviewers = \"\"\"MATCH (a:article),(b:author)\n",
    "WHERE ID(a) = $article_id AND ID(b) = $author_id\n",
    "CREATE p=(a)-[r:reviewed_by]->(b)\n",
    "RETURN p\"\"\"\n",
    "\n",
    "created_review_rel = []\n",
    "\n",
    "with gdb.session() as session:\n",
    "    for article_id in random.sample(article_ids, 1000):\n",
    "        for author_id in random.sample(author_ids, 3):\n",
    "            _out = session.run(q_add_reviewers, article_id=article_id, author_id=author_id)\n",
    "            created_review_rel.append(_out.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p': <Path start=<Node id=2545142 labels={'article'} properties={'volume': '94-17', 'journal': 'Universität Trier, Mathematik/Informatik, Forschungsbericht', 'mdate': neotime.Date(2017, 6, 8), 'year': 1994, 'author': ['Anna Slobodová', 'Christoph Meinel'], 'publtype': 'informal', 'title': 'A Unifying Theoretical Background for Some BDD-based Data Structures', 'article': 401, 'key': 'tr/trier/MI94-17'}> end=<Node id=4832453 labels={'author'} properties={'author': 'Navin Kartik'}> size=1>}]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_review_rel[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.3 Evolving the graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Store the review and the approval sent by each reviewer\n",
    "\n",
    "Since the queries in part B don't need this information, we can store the `review_decision` and the `review_text` as _edge_ attributes of the relation `REVIEWED_BY`.\n",
    "\n",
    "\n",
    "Alternatively, and in the case these reviews were a requirement in part B, they can be implemented by creating a `Review` node, and linking it to articles, in a four step process.\n",
    "\n",
    "1. Create a `Review` article for each `Article` that has reviewers (i.e. is connected to authors by `reviewed_by` edges). Each `Review` node will have an attribute named `review_contents´.\n",
    "2. Attach review to the article\n",
    "3. Attach reviewers to the review instance\n",
    "4. Optional, delete the `reviewed_by` edges from the step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17088467, 17088466, 17088465, 17087513, 17087512]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gdb.session() as session:\n",
    "    out = session.run(\"MATCH p=(:article)-[r:reviewed_by]->(:author) return ID(r)\")\n",
    "    rel_ids = [r[0] for r in out.values()]\n",
    "    \n",
    "rel_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_merge_review_attributes = \"\"\"MATCH p=(:article)-[r:reviewed_by]->(:author)\n",
    "WHERE ID(r) = $rel_id\n",
    "SET r = {review_accepted: $review_accepted, review_text: $review_text}\n",
    "RETURN r\n",
    "\"\"\"\n",
    "\n",
    "created_review_rel_attr = []\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "with gdb.session() as session:\n",
    "    for rel_id in rel_ids:\n",
    "        _out = session.run(q_merge_review_attributes, \n",
    "                    rel_id=rel_id,\n",
    "                    review_accepted=fake.pybool(), \n",
    "                    review_text=fake.texts(nb_texts=1, max_nb_chars=500)[0])\n",
    "        created_review_rel_attr.append(_out.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'r': <Relationship id=17088467 nodes=(<Node id=2470781 labels=set() properties={}>, <Node id=4835571 labels=set() properties={}>) type='reviewed_by' properties={'review_text': 'Continue anything wait local state husband. Officer rather charge specific. Be easy newspaper indicate other.\\nSimply herself training father open. Figure perform participant science way debate. Enough ball dream necessary choose. Late order fact discuss religious reflect.\\nReach under skin person. Interesting name positive training step. Arrive society organization station.\\nBuy read record wall matter management. Our threat same page.\\nDirector purpose team onto.', 'review_accepted': True}>}]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_review_rel_attr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store a reviewing policy for each Journal or Conference\n",
    "\n",
    "This can also be implemented as an `review_policy_min_count` to the `Journal` and `Proceedings` labels. We will set all of them to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gdb.session() as session:\n",
    "    journal_ids = session.run(\"MERGE (n:journal) SET n.review_policy_min_count = 3 return n\").values()\n",
    "    proceeding_ids = session.run(\"MERGE (n:proceedings) SET n.review_policy_min_count = 3 return n\").values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<Node id=4738120 labels={'journal'} properties={'review_policy_min_count': 3, 'journal': 'meltdownattack.com'}>],\n",
       " [<Node id=4738121 labels={'journal'} properties={'review_policy_min_count': 3, 'journal': 'GTE Laboratories Incorporated'}>],\n",
       " [<Node id=4738122 labels={'journal'} properties={'review_policy_min_count': 3, 'journal': 'University of California at Berkeley'}>],\n",
       " [<Node id=4738123 labels={'journal'} properties={'review_policy_min_count': 3, 'journal': 'ANSI X3H2'}>],\n",
       " [<Node id=4738124 labels={'journal'} properties={'review_policy_min_count': 3, 'journal': 'ANSI X2H2'}>]]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<Node id=4685034 labels={'proceedings'} properties={'ee': ['https://doi.org/10.1007/978-3-319-11698-3'], 'editor': ['Barbara Carminati', 'C.-C. Jay Kuo', 'Man Ho Au'], 'year': 2014, 'isbn': ['978-3-319-11697-6'], 'editor-orcid': ['0000-0002-7502-4731', '0000-0003-2068-9530'], 'series-href': ['db/series/lncs/index.html'], 'title': \"Network and System Security - 8th International Conference, NSS 2014, Xi'an, China, October 15-17, 2014, Proceedings\", 'url': 'db/conf/nss/nss2014.html', 'review_policy_min_count': 3, 'volume': '8792', 'mdate': neotime.Date(2019, 5, 14), 'series': ['Lecture Notes in Computer Science'], 'publisher': ['Springer'], 'proceedings': 3546997, 'booktitle': 'NSS', 'key': 'conf/nss/2014'}>],\n",
       " [<Node id=4685035 labels={'proceedings'} properties={'ee': ['https://doi.org/10.1007/978-3-642-38631-2'], 'editor': ['Javier López 0001', 'Ravi Sandhu', 'Xinyi Huang'], 'year': 2013, 'isbn': ['978-3-642-38630-5'], 'series-href': ['db/series/lncs/index.html'], 'title': 'Network and System Security - 7th International Conference, NSS 2013, Madrid, Spain, June 3-4, 2013. Proceedings', 'url': 'db/conf/nss/nss2013.html', 'review_policy_min_count': 3, 'volume': '7873', 'mdate': neotime.Date(2019, 8, 29), 'series': ['Lecture Notes in Computer Science'], 'publisher': ['Springer'], 'proceedings': 3547004, 'booktitle': 'NSS', 'key': 'conf/nss/2013'}>]]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proceeding_ids[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the affiliation of the author to an organization or a company \n",
    "\n",
    "This can be solved by creating an `affiliation_institution_type` attribute, and also an `affiliation_institution_name`. Note that we could have created these as nodes, but the queries from part B do not refer to this information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_set_affiliations = \"\"\"MATCH (n:author)\n",
    "WHERE ID(n) = $author_id\n",
    "SET n = {affiliation_institution_type: $affiliation_institution_type, affiliation_institution_name: $affiliation_institution_name}\n",
    "RETURN n\n",
    "\"\"\"\n",
    "\n",
    "institution_types = ['University', 'Company', 'NGO']\n",
    "created_affiliations = []\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "with gdb.session() as session:\n",
    "    for author_id in author_ids:\n",
    "        _out = session.run(q_set_affiliations, \n",
    "                    author_id=author_id,\n",
    "                    affiliation_institution_name=fake.company(), \n",
    "                    affiliation_institution_type=random.choice(institution_types))\n",
    "        \n",
    "        created_affiliations.append(_out.values())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![schemasafter](schemas/dblp_slim_after/graph.svg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
